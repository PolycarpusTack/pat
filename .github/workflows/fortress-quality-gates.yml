name: 'Fortress Quality Gates & Testing Pipeline'

on:
  push:
    branches: [ main, develop, 'feature/*' ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      coverage_threshold:
        description: 'Minimum test coverage percentage'
        required: false
        default: '90'
        type: string
      run_benchmarks:
        description: 'Run performance benchmarks'
        required: false
        default: 'true'
        type: boolean

env:
  GO_VERSION: '1.21'
  NODE_VERSION: '18'
  COVERAGE_THRESHOLD: ${{ inputs.coverage_threshold || '90' }}

jobs:
  # ================================
  # Code Quality Analysis
  # ================================
  code-quality-analysis:
    name: 'Code Quality Analysis'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
      pull-requests: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Needed for SonarQube analysis
          
      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
          
      - name: Install Go dependencies
        run: go mod download
        
      - name: Install frontend dependencies
        working-directory: ./frontend
        run: npm ci
        
      - name: Run Go static analysis
        run: |
          # Install analysis tools
          go install honnef.co/go/tools/cmd/staticcheck@latest
          go install github.com/securecodewarrior/sast-scan@latest
          go install golang.org/x/tools/cmd/goimports@latest
          
          # Run static analysis
          echo "::group::Go Static Analysis"
          staticcheck -checks=all ./...
          echo "::endgroup::"
          
          # Check code formatting
          echo "::group::Go Code Formatting"
          if [ "$(goimports -l . | wc -l)" -gt 0 ]; then
            echo "Code is not properly formatted:"
            goimports -l .
            exit 1
          fi
          echo "Code formatting: PASSED"
          echo "::endgroup::"
          
      - name: Run Go linting
        uses: golangci/golangci-lint-action@v3
        with:
          version: latest
          args: --timeout=10m --config=.golangci.yml --issues-exit-code=1
          
      - name: Run frontend linting
        working-directory: ./frontend
        run: |
          echo "::group::Frontend Linting"
          npm run lint
          npm run type-check
          echo "::endgroup::"
          
      - name: Run code complexity analysis
        run: |
          echo "::group::Code Complexity Analysis"
          go install github.com/fzipp/gocyclo/cmd/gocyclo@latest
          
          # Check cyclomatic complexity (threshold: 10)
          COMPLEX_FUNCS=$(gocyclo -over 10 . | wc -l)
          if [ "$COMPLEX_FUNCS" -gt 0 ]; then
            echo "Functions with high cyclomatic complexity (>10):"
            gocyclo -over 10 .
            echo "Consider refactoring these functions"
            # Don't fail build, just warn for now
          fi
          echo "::endgroup::"
          
      - name: Check for TODO/FIXME comments
        run: |
          echo "::group::TODO/FIXME Analysis"
          TODO_COUNT=$(grep -r "TODO\|FIXME\|HACK" --include="*.go" --include="*.ts" --include="*.tsx" . | wc -l)
          if [ "$TODO_COUNT" -gt 50 ]; then
            echo "::warning::High number of TODO/FIXME comments ($TODO_COUNT). Consider addressing some of them."
          fi
          echo "TODO/FIXME count: $TODO_COUNT"
          echo "::endgroup::"
          
      - name: SonarQube analysis
        uses: sonarqube-quality-gate-action@master
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

  # ================================
  # Unit Testing
  # ================================
  unit-tests:
    name: 'Unit Tests'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        go-version: ['1.21', '1.22']
        
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ matrix.go-version }}
          
      - name: Install dependencies
        run: go mod download
        
      - name: Run unit tests with coverage
        run: |
          echo "::group::Go Unit Tests"
          mkdir -p coverage
          
          # Run tests with coverage
          go test -v -race -coverprofile=coverage/coverage.out -covermode=atomic ./...
          
          # Generate coverage report
          go tool cover -html=coverage/coverage.out -o coverage/coverage.html
          
          # Extract coverage percentage
          COVERAGE=$(go tool cover -func=coverage/coverage.out | grep "total:" | awk '{print $3}' | sed 's/%//')
          echo "Test coverage: ${COVERAGE}%"
          
          # Check coverage threshold
          if (( $(echo "$COVERAGE < $COVERAGE_THRESHOLD" | bc -l) )); then
            echo "::error::Test coverage ($COVERAGE%) is below threshold ($COVERAGE_THRESHOLD%)"
            exit 1
          fi
          
          echo "COVERAGE_PERCENTAGE=$COVERAGE" >> $GITHUB_ENV
          echo "::endgroup::"
          
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage/coverage.out
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: true
          
      - name: Upload coverage reports as artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports-go-${{ matrix.go-version }}
          path: coverage/
          
      - name: Comment PR with coverage
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const coverage = process.env.COVERAGE_PERCENTAGE;
            const threshold = process.env.COVERAGE_THRESHOLD;
            const status = parseFloat(coverage) >= parseFloat(threshold) ? '✅' : '❌';
            
            const comment = `## 🧪 Test Coverage Report
            
            **Go ${{ matrix.go-version }}:** ${status} **${coverage}%** (threshold: ${threshold}%)
            
            ${parseFloat(coverage) >= parseFloat(threshold) ? 
              '✅ Coverage threshold met!' : 
              '❌ Coverage below threshold - please add more tests'}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  # ================================
  # Frontend Testing
  # ================================
  frontend-tests:
    name: 'Frontend Tests'
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
          
      - name: Install dependencies
        working-directory: ./frontend
        run: npm ci
        
      - name: Run frontend tests
        working-directory: ./frontend
        run: |
          echo "::group::Frontend Unit Tests"
          npm run test:coverage
          echo "::endgroup::"
          
      - name: Upload frontend coverage
        uses: codecov/codecov-action@v4
        with:
          file: ./frontend/coverage/lcov.info
          flags: frontend
          name: codecov-frontend

  # ================================
  # Integration Testing
  # ================================
  integration-tests:
    name: 'Integration Tests'
    runs-on: ubuntu-latest
    needs: [unit-tests]
    
    services:
      postgres:
        image: postgres:15.9-alpine
        env:
          POSTGRES_PASSWORD: fortress_test_password
          POSTGRES_USER: fortress_test_user
          POSTGRES_DB: fortress_test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7.4-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          
      - name: Install dependencies
        run: go mod download
        
      - name: Wait for services
        run: |
          echo "Waiting for PostgreSQL to be ready..."
          while ! pg_isready -h localhost -p 5432 -U fortress_test_user; do
            sleep 2
          done
          
          echo "Waiting for Redis to be ready..."
          while ! redis-cli -h localhost -p 6379 ping; do
            sleep 2
          done
          
      - name: Run database migrations
        env:
          DATABASE_URL: postgresql://fortress_test_user:fortress_test_password@localhost:5432/fortress_test_db?sslmode=disable
        run: |
          echo "::group::Database Migrations"
          go run cmd/migrate/main.go up
          echo "::endgroup::"
          
      - name: Run integration tests
        env:
          DATABASE_URL: postgresql://fortress_test_user:fortress_test_password@localhost:5432/fortress_test_db?sslmode=disable
          REDIS_URL: redis://localhost:6379/0
        run: |
          echo "::group::Integration Tests"
          go test -v -tags=integration ./test/integration/...
          echo "::endgroup::"
          
      - name: Run API contract tests
        env:
          DATABASE_URL: postgresql://fortress_test_user:fortress_test_password@localhost:5432/fortress_test_db?sslmode=disable
          REDIS_URL: redis://localhost:6379/0
        run: |
          echo "::group::API Contract Tests"
          go test -v -tags=contract ./test/api/...
          echo "::endgroup::"

  # ================================
  # Performance Testing
  # ================================
  performance-tests:
    name: 'Performance Tests & Benchmarks'
    runs-on: ubuntu-latest
    if: github.event.inputs.run_benchmarks == 'true' || github.event_name == 'push'
    needs: [unit-tests]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          
      - name: Install dependencies
        run: go mod download
        
      - name: Run Go benchmarks
        run: |
          echo "::group::Go Benchmarks"
          mkdir -p benchmarks
          
          # Run benchmarks and save results
          go test -bench=. -benchmem -run=^$ ./... > benchmarks/go_benchmarks.txt
          
          # Display key benchmark results
          echo "Key benchmark results:"
          cat benchmarks/go_benchmarks.txt
          echo "::endgroup::"
          
      - name: Performance regression check
        if: github.event_name == 'pull_request'
        run: |
          echo "::group::Performance Regression Check"
          # In a real scenario, this would compare against baseline performance
          # For now, we'll check that critical operations meet performance requirements
          
          # Example: Check that email processing takes < 50ms on average
          SMTP_PERF=$(grep "BenchmarkSMTPServer" benchmarks/go_benchmarks.txt || echo "")
          if [ -n "$SMTP_PERF" ]; then
            echo "SMTP Server benchmark: $SMTP_PERF"
          fi
          
          # Example: Check memory usage is reasonable
          MEMORY_USAGE=$(grep "allocs/op" benchmarks/go_benchmarks.txt | head -5)
          echo "Memory allocation samples:"
          echo "$MEMORY_USAGE"
          echo "::endgroup::"
          
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmarks/

  # ================================
  # Security Testing
  # ================================
  security-tests:
    name: 'Security Tests'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          
      - name: Run GoSec security scanner
        run: |
          echo "::group::GoSec Security Analysis"
          go install github.com/securecodewarrior/gosec/v2/cmd/gosec@latest
          gosec -fmt sarif -out gosec-results.sarif ./...
          echo "::endgroup::"
          
      - name: Upload GoSec results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: gosec-results.sarif
          
      - name: Run dependency vulnerability check
        run: |
          echo "::group::Dependency Vulnerability Check"
          go install golang.org/x/vuln/cmd/govulncheck@latest
          govulncheck ./...
          echo "::endgroup::"

  # ================================
  # Test Results Aggregation
  # ================================
  test-results:
    name: 'Test Results & Quality Gate'
    runs-on: ubuntu-latest
    needs: [code-quality-analysis, unit-tests, frontend-tests, integration-tests, performance-tests, security-tests]
    if: always()
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        
      - name: Generate test summary
        run: |
          echo "## 🏰 Fortress Quality Gate Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Code Quality Analysis:** ${{ needs.code-quality-analysis.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Unit Tests:** ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Frontend Tests:** ${{ needs.frontend-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Integration Tests:** ${{ needs.integration-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Performance Tests:** ${{ needs.performance-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Security Tests:** ${{ needs.security-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
      - name: Determine overall quality gate status
        id: quality-gate
        run: |
          # Check if all critical tests passed
          CRITICAL_TESTS=("code-quality-analysis" "unit-tests" "integration-tests" "security-tests")
          ALL_PASSED=true
          
          for test in "${CRITICAL_TESTS[@]}"; do
            case $test in
              "code-quality-analysis")
                if [ "${{ needs.code-quality-analysis.result }}" != "success" ]; then
                  ALL_PASSED=false
                  echo "❌ Code quality analysis failed"
                fi
                ;;
              "unit-tests")
                if [ "${{ needs.unit-tests.result }}" != "success" ]; then
                  ALL_PASSED=false
                  echo "❌ Unit tests failed"
                fi
                ;;
              "integration-tests")
                if [ "${{ needs.integration-tests.result }}" != "success" ]; then
                  ALL_PASSED=false
                  echo "❌ Integration tests failed"
                fi
                ;;
              "security-tests")
                if [ "${{ needs.security-tests.result }}" != "success" ]; then
                  ALL_PASSED=false
                  echo "❌ Security tests failed"
                fi
                ;;
            esac
          done
          
          if [ "$ALL_PASSED" = true ]; then
            echo "✅ All critical quality gates passed!"
            echo "status=passed" >> $GITHUB_OUTPUT
            echo "### ✅ **QUALITY GATE: PASSED**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "🎉 **Pat Fortress is ready for deployment!**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Quality Metrics:**" >> $GITHUB_STEP_SUMMARY
            echo "- Test Coverage: ≥${{ env.COVERAGE_THRESHOLD }}%" >> $GITHUB_STEP_SUMMARY
            echo "- Code Quality: ✅ Passed" >> $GITHUB_STEP_SUMMARY
            echo "- Security: ✅ No critical vulnerabilities" >> $GITHUB_STEP_SUMMARY
            echo "- Performance: ✅ Benchmarks within acceptable range" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Quality gate failed!"
            echo "status=failed" >> $GITHUB_OUTPUT
            echo "### ❌ **QUALITY GATE: FAILED**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "🚫 **Deployment blocked until issues are resolved**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Required Actions:**" >> $GITHUB_STEP_SUMMARY
            echo "1. Fix failing tests" >> $GITHUB_STEP_SUMMARY
            echo "2. Address security vulnerabilities" >> $GITHUB_STEP_SUMMARY
            echo "3. Improve code quality issues" >> $GITHUB_STEP_SUMMARY
            echo "4. Ensure test coverage meets threshold" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
          
      - name: Create quality gate status badge
        run: |
          STATUS="${{ steps.quality-gate.outputs.status }}"
          COLOR=$([ "$STATUS" = "passed" ] && echo "brightgreen" || echo "red")
          LABEL="Quality Gate"
          MESSAGE=$([ "$STATUS" = "passed" ] && echo "PASSED" || echo "FAILED")
          
          curl -X GET "https://img.shields.io/badge/$LABEL-$MESSAGE-$COLOR" -o quality-gate-badge.svg
          
      - name: Upload quality gate badge
        uses: actions/upload-artifact@v4
        with:
          name: quality-gate-badge
          path: quality-gate-badge.svg
          
      - name: Notify on failure
        if: failure() && (github.event_name == 'push' && github.ref == 'refs/heads/main')
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          channel: '#fortress-alerts'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          text: |
            🚨 **FORTRESS QUALITY GATE FAILURE** 🚨
            
            Quality gate failed on main branch!
            
            **Repository:** ${{ github.repository }}
            **Commit:** ${{ github.sha }}
            **Author:** ${{ github.actor }}
            
            **Failed Checks:**
            - Code Quality: ${{ needs.code-quality-analysis.result }}
            - Unit Tests: ${{ needs.unit-tests.result }}
            - Integration Tests: ${{ needs.integration-tests.result }}
            - Security Tests: ${{ needs.security-tests.result }}
            
            Please investigate and fix immediately!
            
      - name: Report success
        if: success() && (github.event_name == 'push' && github.ref == 'refs/heads/main')
        uses: 8398a7/action-slack@v3
        with:
          status: success
          channel: '#fortress-updates'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          text: |
            ✅ **Fortress Quality Gate: PASSED** ✅
            
            All quality checks passed successfully!
            
            **Repository:** ${{ github.repository }}
            **Commit:** ${{ github.sha }}
            **Coverage:** ${{ env.COVERAGE_PERCENTAGE }}%
            
            🚀 Ready for deployment!